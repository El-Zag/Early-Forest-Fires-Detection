{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Training.ipynb","provenance":[{"file_id":"1_zqnBBc0nVF7uV0L4dLvNzZGaRzEcQ-t","timestamp":1629636594328}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hNuxBfel7Fek"},"source":["# **Training à l'aide de la plateforme Detectron2**"]},{"cell_type":"markdown","metadata":{"id":"7wd7CNfR8N4m"},"source":["**Detectron2** est une plateforme de recherche et detection d'objet crée par Facebook. Elle est codée sur Pytorch, et permet donc d'utiliser un GPU et d'être plus rapide. Je l'utilise pour implémenter un Faster R-CNN. Il pourrait être interessant d'explorer d'autres modeles de détection, comme des  Mask R-CNN.\n","\n","[**Documentation de Detectron**](https://detectron2.readthedocs.io/en/latest/index.html)\n"]},{"cell_type":"code","metadata":{"id":"dE5Ud-yXuTfW"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jw-dwwdQvS93"},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Yt7CdObu_Ee"},"source":["# Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"lAbnrtQiGfkZ"},"source":["## Installations"]},{"cell_type":"code","metadata":{"id":"a_88NsjuYBY2"},"source":["!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n","!pip install cython pyyaml==5.1\n","!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cQ4Q_yghZ8eN"},"source":["import torch, torchvision\n","print(torch.__version__, torch.cuda.is_available())\n","!gcc --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LHG2j_U4YRxd"},"source":["# Installer detectron2\n","!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nWUf7MwtNaN5"},"source":["## Imports et Dossiers\n","\n"]},{"cell_type":"code","metadata":{"id":"dYOMvYRmYXyZ"},"source":["import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","import numpy as np\n","import cv2\n","import random\n","from google.colab.patches import cv2_imshow\n","import json\n","\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog\n","from detectron2.structures import BoxMode\n","from detectron2.data import DatasetCatalog, MetadataCatalog"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3yLFCsAPbXm9"},"source":["# Data est le dosssier mère contenant les sous dossiers test et train\n","Data = \"drive/MyDrive/Mines Nancy/Depinfo/Projet/Faster_rCNN/Data_detectron\"\n","\n","# Dossiers de train et de test créés pendant le Preprocessing\n","train_path = Data + \"/train\"\n","test_path = Data + \"/test\"\n","\n","COLORS = ['b', 'r', 'm', 'y', 'w', 'k']\n","category_id = {\"smoke\" : \"0\"}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"znCbHTmp5Qzl"},"source":["## Enregistrement du Dataset\n","\n"]},{"cell_type":"markdown","metadata":{"id":"OotROX-3FxEu"},"source":["Il y a différents types de format pour les bbox. J'ai utilisé le formax **BoxMode.XYWH_ABS**, c'est à dire x0, y0, largeur, hauteur. Il faut enregistrer le dataset pour utiliser Detectron, dans leur DatasetCatalog, ainsi que les meta données dans MetadataCatalog (voir la [documentation](https://detectron2.readthedocs.io/en/latest/index.html)).\n"]},{"cell_type":"code","metadata":{"id":"SLFK99iaOHnJ"},"source":["def get_dicts(imgdir):\n","    json_file = imgdir+\"/dataset_total.json\"\n","    with open(json_file) as f:\n","        dataset_dicts = json.load(f)\n","    for i in dataset_dicts:\n","        filename = i[\"file_name\"] \n","        i[\"file_name\"] = imgdir+\"/\"+filename \n","        for j in i[\"annotations\"]:\n","            j[\"bbox_mode\"] = BoxMode.XYWH_ABS\n","            j[\"category_id\"] = int(j[\"category_id\"])\n","    return dataset_dicts\n","\n","# Remplacer train et test par les noms des dossiers de train et test si ils ne s'appelent pas ainsi\n","# Il faudra modifier également data_dict_train et data_dict_test pour changer le dernier mot en le nom des dossiers dans le reste du notebook\n","for d in [\"train\", \"test\"]:\n","    DatasetCatalog.register(\"data_dict_\" + d, lambda d=d: get_dicts(Data + \"/\" + d))\n","    MetadataCatalog.get(\"data_dict_\" + d).set(thing_classes=[\"smoke\"])\n","metadata_dict = MetadataCatalog.get(\"data_dict_train\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r0LgkewcF9rS"},"source":["## Visualiser le Dataset"]},{"cell_type":"markdown","metadata":{"id":"AC_N3j0gGLD4"},"source":["Code pour visualiser les images avec le Visualizer. Ici, on visualise 10 images de training."]},{"cell_type":"code","metadata":{"id":"8k2CiPMPAxJc"},"source":["dataset_dicts = get_dicts(train_path)\n","\n","for i in range(10):\n","    d = dataset_dicts[i]\n","    img = cv2.imread(d[\"file_name\"])\n","    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata_dict)\n","    vis = visualizer.draw_dataset_dict(d)\n","    cv2_imshow(vis.get_image()[:, :, ::-1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cf5oFNhJGsro"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"t4WDlOaA9P2g"},"source":["# On importe un module d'evaluation, en utilisant la validation de COCO\n","from detectron2.engine import DefaultTrainer\n","from detectron2.evaluation import COCOEvaluator\n","\n","class CocoTrainer(DefaultTrainer):\n","\n","  @classmethod\n","  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n","\n","    if output_folder is None:\n","        os.makedirs(Data + \"/coco_eval_4\", exist_ok=True)\n","        output_folder = Data + \"/coco_eval_4\"\n","\n","    return COCOEvaluator(dataset_name, cfg, False, output_folder)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IejApXZlHiJl"},"source":["Configuration des paramètres et hyperparamètres.\n","J'utilise le modele **\"faster_rcnn_R_50_FPN_3x.yaml\"**."]},{"cell_type":"code","metadata":{"id":"IjzTONK4OcrO"},"source":["from detectron2.engine import DefaultTrainer\n","from detectron2.config import get_cfg\n","import os\n","\n","cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n","cfg.DATASETS.TRAIN = (\"data_dict_train\",)\n","cfg.DATASETS.TEST = (\"data_dict_test\",)\n","\n","cfg.DATALOADER.NUM_WORKERS = 4\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n","cfg.SOLVER.IMS_PER_BATCH = 4\n","\n","cfg.SOLVER.BASE_LR = 0.0125 \n","cfg.SOLVER.MAX_ITER = 3000\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256  \n","\n","# Nombre de classes, ici 1\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n","\n","cfg.TEST.EVAL_PERIOD = 500\n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","trainer = CocoTrainer(cfg) \n","trainer.resume_or_load(resume=False)\n","\n","#  Lance l'entrainement\n","trainer.train()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"78cAHQP5ITDf"},"source":["Permet d'analyser comment l'entrainement s'est passé"]},{"cell_type":"code","metadata":{"id":"mKq_rkWL_PWx"},"source":["%load_ext tensorboard\n","%tensorboard --logdir output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z1sFTHbVvRh8"},"source":["# Analyse"]},{"cell_type":"markdown","metadata":{"id":"9EIsGLmbIpU0"},"source":["## Inference sur le Dataset de Test avec le modèle entrainé"]},{"cell_type":"markdown","metadata":{"id":"j77LhG3EI4wr"},"source":["Un dossier output est sauvegardé dans le stokage local de google colab avec les poids du modèle entrainé. Il faut le sauvegarder pour réutiliser le modèle. "]},{"cell_type":"code","metadata":{"id":"L_q_RZNNQEjU"},"source":["cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n","\n","# Permet de fixer le score minimal d'acceptation d'une image\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5 \n","cfg.DATASETS.TEST = (\"data_dict_test\", )\n","predictor = DefaultPredictor(cfg)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6qT0J_Si14bL"},"source":["from shutil import copytree\n","# On copie le dossier d'output contenant les poids au dossier dest. \n","src = cfg.OUTPUT_DIR\n","dest = \"drive/MyDrive/Mines Nancy/Depinfo/Projet/Faster_rCNN/Data_detectron/trained_model\"\n","destination = copytree(src, dest)\n","print(\"Les poids ont été copié vers : \", destination)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"QWvnrdOb4tUV"},"source":["# Affiche les resultats sur des images aléatoires\n","\n","from detectron2.utils.visualizer import ColorMode\n","dataset_dicts = get_dicts(test_path)\n","for d in random.sample(dataset_dicts, 10):    \n","    im = cv2.imread(d[\"file_name\"])\n","    outputs = predictor(im)\n","    v = Visualizer(im[:, :, ::-1],\n","                   metadata=metadata_dict, \n","                   scale=0.8,\n","                   instance_mode=ColorMode.IMAGE \n","    )\n","\n","    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","    cv2_imshow(v.get_image()[:, :, ::-1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VTouJ5BnJ3GN"},"source":["## Evaluation du modèle"]},{"cell_type":"markdown","metadata":{"id":"kFkj-PntKC6w"},"source":["Evaluation selon les critères COCO, avec le mAP. "]},{"cell_type":"code","metadata":{"id":"r4ZzQJLR2kD8"},"source":["from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n","from detectron2.data import build_detection_test_loader\n","evaluator = COCOEvaluator(\"data_dict_test\", cfg, False, output_dir=\"/output/\")\n","val_loader = build_detection_test_loader(cfg, \"data_dict_test\")\n","inference_on_dataset(predictor.model, val_loader, evaluator)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ntcahbjPtRuk"},"source":["## Codes en cours"]},{"cell_type":"code","metadata":{"id":"dVDDgF7zgneN"},"source":["\n","# Affiche les bboxs détectées sur les images de test\n","import detectron2.structures as structures\n","dataset_dicts = get_dicts(test_path)\n","for i in range(10) :\n","    d = dataset_dicts[i]\n","    im = cv2.imread(d[\"file_name\"])\n","    output = predictor(im)\n","    bbox = [ float(d['annotations'][0]['bbox'][i]) for i in range(4)]\n","\n","    cuda0 = torch.device('cuda:0')\n","    bboxes_pred = outputs[\"instances\"].pred_boxes\n","    gt = torch.empty_like(bboxes_pred.tensor)\n","\n","\n","    for j in range(4):\n","        gt[0][j] = bbox[j]\n","\n","    bboxes_gt = structures.Boxes(gt)\n","\n","    IOUs = structures.pairwise_iou(bboxes_gt, bboxes_pred)\n","    if IOUs[0][0] > 0.5 :\n","      print(bboxes_gt, bboxes_pred, IOUs)\n","      print(output)\n","      print(d)"],"execution_count":null,"outputs":[]}]}